<!-- 4주차_함수.md -->
# Python Study 4주차: 데이터 분석 라이브러리

## 데이터 분석을 위한 라이브러리
지난 3주 간의 내용을 통해 기본적인 파이썬 문법을 학습하고 함수를 사용하는 것까지 마쳤다. 함수를 직접 만드는 능력은 중요하지만 처음부터 모든 것을 만들 필요는 없다. 이미 다른 사람들이 만들어놓은 훌륭한 함수를 사용하는 것도 능력이다. 스터디의 후반부에서는 데이터 분석에서 자주 사용하는 라이브러리를 소개하고 해당 라이브러리를 사용하는 방법을 배운다. 

<br/>

### 데이터 처리: Numpy, Pandas
대규모 데이터 처리를 위해서는 행렬 연산이 유리한데 이를 가장 잘 사용하는 언어가 MATLAB일 것이다. 많은 대학교 및 연구소에서 MATLAB을 사용하는 이유가 있다. 파이썬 자체적으로는 행렬 연산을 할 수 있는 자료형이 없다. 그래서 파이썬 프로그래머들은 파이썬에서 MATLAB의 행렬 연산을 흉내낼 수 있는 라이브러리를 만들게 되는데 이 라이브러리가 Numpy다. 행렬 연산은 처리 속도가 매우 빠르고, 다양한 선형 대수적 기법을 사용하는데 유리하다. 

반면 통계 전문 언어인 R에서는 데이터프레임이라는 자료형을 사용한다. 데이터프레임은 행과 열로 이루어진 2차원 데이터의 열마다 이름을 붙여준 것이다. 이러한 방법으로는 선형대수적 연산이 어려워지지만 각 변수를 하나의 열로서 이름 붙이기에 많은 변수를 보기 쉽게 관리할 수 있다. 파이썬은 R의 데이터프레임도 가져와 Pandas라는 라이브러리를 만든다. 

위의 설명을 통해 왜 파이썬을 이용한 데이터 분석에서는 Numpy와 Pandas를 필수적으로 익혀야하는지 알 수 있다. 이 글은 이미지 처리보다는 행동 데이터 분석을 목적으로 하기 때문에 Pandas를 위주로 설명한다.

<br/>

## 데이터 불러오기
### pd.DataFrame(): 데이터프레임 만들기
```python
import pandas as pd

# 민트 초코에 대한 10명의 선호도 (10점 만점)
Mincho = [
    9.5, 
    5.6, 
    7.8, 
    6.1, 
    4.9, 
    7.0, 
    6.5, 
    5.8, 
    6.2, 
    6.8]
data = pd.DataFrame(Mincho)
```

pandas는 `pd`라는 약어로 주로 불러온다. 일단 우리가 잘 아는 리스트 자료형을 만들자. `pd.DataFrame()`을 사용하면 해당 리스트 자료형을 데이터프레임 자료형으로 만들 수 있다. 데이터프레임 자료형은 리스트와 달리 행과 열의 형태로 자료를 저장한다. 

<br/>

### pd.read_csv(): csv 파일 데이터프레임으로 불러오기
```python
data = pd.read_csv('pandas_practice.csv')
data = pd.read_csv('파일 경로', delimiter='\t')
data = pd.read_csv('파일 경로', header=None)
```

직접 리스트나 딕셔너리를 데이터프레임으로 만들 수도 있지만 보다 일반적으로는 외부 자료를 불러와서 분석하게 된다. 자료 포맷은 다양하지만 많은 경우 CSV(Comma-Seperated Values) 파일을 사용하게 된다. pandas에서는 자체적으로 csv파일을 읽을 수 있는 함수를 제공한다.

`pd.read_csv()` 함수의 파라미터를 바꿔주는 것으로 불러오기 옵션을 조절할 수 있다. 자주 사용하는 옵션 두개만 소개한다.  `delimiter` 옵션으로 데이터 값을 구분하는 구분자를 지정해줄 수 있다. 이를 통해 TSV(Tab-Seperated Values) 파일 등을 불러오는 것도 가능하다. `header` 옵션을 조절하면 데이터의 맨 위를 변수명으로 지정할 것인지 아닌지 정할 수 있다.

<br/>

## 데이터 살펴보기
### data.shape: 데이터 크기 확인
```python
data.shape      # (360, 3)
data.head(n=10)
data.tail(n=10)
```

데이터를 얻고 가장 먼저 해야할 것은 무엇인가? 이 질문에 대한 나의 답은 데이터의 크기를 확인하라는 것이다. 이러한 방법은 데이터의 크기가 클수록 유용하다. 크기가 작은 데이터는 눈으로 보는 것으로 쉽게 오류를 찾을 수 있지만 크기가 큰 데이터는 그게 어렵다. `data.shape`를 통해 2차원 데이터인 데이터프레임의 행과 열을 확인할 수 있다.

이 글에서 사용하는 샘플 데이터는 참가자 한명이 특정 과제를 수행한 결과이다. 행의 총 개수는 360으로 이는 참가자가 360번 특정 과제를 수행했음을 나타낸다. 열의 총 개수는 3인데 이에 참가자 번호, 정답여부, 반응시간으로 구성되어 있다. 

데이터의 크기가 자신의 생각과 일치한다면 데이터의 앞과 뒤를 확인하자. 많은 경우 오류는 데이터의 앞과 뒤를 보는 것으로 확인할 수 있다. 이를 위해 `data.head()`, `data.tail()`을 사용할 수 있다. 괄호 안에 값을 넣어주면 앞에서부터(뒤에서부터) 해당 숫자만큼의 값을 반환한다.

<br/>

```python
data.columns    
# Index(['sn', 'cor', 'rt'], dtype='object')
```

데이터프레임은 행과 열로 이루어진 2차원 데이터이다. 행은 데이터를 몇번째 시행에서 얻은 것인지 알려준다. 우리가 보다 관심 있는 것은 열이다. 각 열이 관심 있는 변수이기 때문에 열 제목을 확인하는 것으로 데이터에 어떤 변수들이 들어있는지 확인할 수 있다. 제대로 된 분석을 하기 전에 `data.columns`를 사용해 이 데이터는 어떤 변수로 이루어졌는지 확인하자.

<br/>

### data.describe(): 요약 통계량
```python
data.mean()
data.sum() 
data.max()
data.min()
data.var() 
data.std() 

data.describe()
#           sn      cor         rt
# count     360.0	360.000000	350.000000
# mean      1.0     0.994444	0.307389
# std	    0.0     0.074432	0.330269
# min	    1.0     0.000000	0.003000
# 25%	    1.0	    1.000000	0.203000
# 50%	    1.0	    1.000000	0.259000
# 75%	    1.0	    1.000000	0.326000
# max	    1.0	    1.000000	4.560000
```

데이터의 성질을 살펴보는 가장 빠른 방법은 요약 통계량을 보는 것이다. 평균, 합, 최대값, 최소값 등을 쉽게 확인할 수 있다. 이 모든 것을 한 눈에 보고 싶다면 `data.describe()` 함수를 사용하자.

요약 통계량을 통해 우리는 1번 참가자의 과제 정확률이 99.44%고 반응 시간의 평균은 307ms임을 확인할 수 있다. 또한 과제 중 10번은 반응하지 않은 것을 알 수 있다(rt의 count값을 확인하라).

<br/>

## 데이터 주무르기
### data.isna(): 결측값 처리
```python
data.isna() # 결측값 확인

# 	sn	    cor	    rt
# 0	False	False	False
# 1	False	False	False
# 2	False	False	False
# 3	False	False	False
# 4	False	False	True
```
요약 통계량을 통해 데이터에 결측값이 있는 것을 확인했다. 그런 간접적인 방법 말고 조금 더 직접적으로 확인할 수는 없을까? `data.isna()`를 사용하면 결측값을 쉽게 찾을 수 있다. 결과로 얻는 것은 결측값이 있는 위치만 True로 되어있는 진리 행렬이다. 

<br/>

```python
replaced_data = data.fillna(0)
dropped_data = data.dropna(
    axis='rows', # 옵션: 'rows', 'columns'
    how='any' # 옵션: 'any', 'all'
)
dropped_data = dropped_data.reset_index()
```
결측값의 처리 또한 데이터에 대한 가공이기 때문에 쉽게 결정할 수 없다. 일반적으로는 결측값을 다른 값으로 대체하거나 결측값이 있는 시행을 전부 제거해버리는 방식을 사용한다. 전자를 위해서는 `data.fillna(대체할 값)`을 사용하고 후자를 위해서는 `data.dropna()`를 사용하면 된다.

`data.dropna()`를 써서 결측값을 제거하는 경우를 조금 더 설명해보자. `axis` 옵션을 사용하면 제거할 위치가 열인지 행인지 정할 수 있다. 대부분의 경우 결측값이 있는 시행만 제거하기 때문에 기본값은 행이다. `how`는 결측값이 하나만 있어도 제거하는지 아니면 해당 행(혹은 열)이 전부 결측값이어야 제거하는지 물어본다.

또한 결측값을 제거하면 행 번호도 일부 제거된다. 우리의 새로운 데이터에서는 4행이 존재하지 않게되는데 이렇게 되면 추후에 귀찮아지니 `data.reset_index()` 함수를 써서 인덱스를 업데이트 해주자.

<br/>

### 데이터프레임 슬라이싱
```python
dropped_data['rt']
dropped_data['rt'][3:5]
```
전체 데이터 중 일부를 추출하는 것은 데이터 전처리의 많은 부분을 차지한다. 리스트와 마찬가지로 전체 중 일부를 뽑아내는 것을 슬라이싱이라고 부른다. 데이터프레임은 각 열에 이름이 붙어있기 때문에 열 이름을 지정해주는 것만으로 간단히 특정 열을 선택할 수 있다. 

```python
dropped_data['age'] = 22
dropped_data['age'] # Broadcast
```
결측값은 제거했는데 이젠 새로운 값을 추가하고 싶어졌다. 지금의 데이터에는 참가자의 나이가 없는데 새로운 열을 만들어 참가자의 나이를 추가한다고 해보자. 기본적으로 데이터프레임의 각 열은 딕셔너리와 동일한 방법으로 가져올 수 있다. 

<br/>

### 2개 이상의 데이터프레임 합치기
```python
data2 = pd.read_csv('pandas_practice2.csv')
data = pd.concat([data, data2])
```

보통은 참가자 각각 데이터 파일을 저장한다. 이걸 분석하려면 각 데이터 파일을 데이터프레임으로 불러온 뒤 합쳐줘야 한다. 데이터 파일을 불러오는 것은 위에서 설명한대로 하면 되고 합치는걸 해보자. `pd.concat(합칠 데이터프레임 리스트)` 함수로 쉽게 합칠 수 있다. 2개 이상의 데이터프레임을 합치는 것도 가능하다.

<br/>

```python
data.describe()
data.groupby('sn').describe()
```
`data.describe()`로는 전체 요약 통계량만 확인할 수 있기 때문에 일반적인 합친 데이터프레임에 사용하기에는 좋지 않다. 우리는 각 참가자에 번호를 부여했기 때문에 해당 번호에 따라서 결과를 나눠보자. `data.groupby('라벨 열')`을 사용하면 각 참가자 혹은 집단 별 통계량을 확인할 수 있다.

<br/>

### 데이터 저장하기
```python
data.to_csv('경로', index=False)
```
데이터에 대한 조작이 끝나면 데이터프레임을 새로운 csv파일로 저장하고 싶을 수 있다. `.to_csv()`를 사용하면 데이터프레임을 CSV 파일로 간단히 저장할 수 있다. 